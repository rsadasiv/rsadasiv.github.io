<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>WikipediaGlossAnnotator.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">OOP Core NLP</a> &gt; <a href="index.source.html" class="el_package">io.outofprintmagazine.nlp.pipeline.annotators</a> &gt; <span class="el_source">WikipediaGlossAnnotator.java</span></div><h1>WikipediaGlossAnnotator.java</h1><pre class="source lang-java linenums">/*******************************************************************************
 * Copyright (C) 2020 Ram Sadasiv
 * 
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 * 
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 * 
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.
 ******************************************************************************/
package io.outofprintmagazine.nlp.pipeline.annotators;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.Annotator;
import edu.stanford.nlp.pipeline.CoreDocument;
import edu.stanford.nlp.pipeline.CoreSentence;
import io.outofprintmagazine.nlp.pipeline.scorers.Scorer;
import io.outofprintmagazine.nlp.pipeline.scorers.StringScorer;
import io.outofprintmagazine.nlp.pipeline.serializers.Serializer;
import io.outofprintmagazine.nlp.pipeline.serializers.StringSerializer;
import io.outofprintmagazine.nlp.utils.WikipediaUtils2;

public class WikipediaGlossAnnotator extends AbstractPosAnnotator implements Annotator, OOPAnnotator {
	
	@SuppressWarnings(&quot;unused&quot;)
<span class="fc" id="L40">	private static final Logger logger = LogManager.getLogger(WikipediaGlossAnnotator.class);</span>
	
	@Override
	protected Logger getLogger() {
<span class="nc" id="L44">		return logger;</span>
	}
	
	public WikipediaGlossAnnotator() {
<span class="fc" id="L48">		super();</span>
<span class="fc" id="L49">		this.setTags(Arrays.asList(&quot;NN&quot;,&quot;NNS&quot;, &quot;NNP&quot;, &quot;NNPS&quot;));</span>
<span class="fc" id="L50">		this.setScorer((Scorer)new StringScorer(this.getAnnotationClass()));</span>
<span class="fc" id="L51">		this.setSerializer((Serializer)new StringSerializer(this.getAnnotationClass()));		</span>
<span class="fc" id="L52">	}</span>
	
	@Override
	public Class getAnnotationClass() {
<span class="fc" id="L56">		return io.outofprintmagazine.nlp.pipeline.OOPAnnotations.OOPWikipediaGlossAnnotation.class;</span>
	}
	
	@Override
	public void annotate(Annotation annotation) {
<span class="fc" id="L61">		CoreDocument document = new CoreDocument(annotation);</span>
<span class="fc" id="L62">		List&lt;String&gt; queries = new ArrayList&lt;String&gt;();</span>
<span class="fc bfc" id="L63" title="All 2 branches covered.">		for (CoreSentence sentence : document.sentences()) {</span>
<span class="fc bfc" id="L64" title="All 2 branches covered.">			for (CoreLabel token : sentence.tokens()) {</span>
<span class="fc" id="L65">				String topic = scoreLemma(token);</span>
<span class="fc bfc" id="L66" title="All 2 branches covered.">				if (topic != null) {</span>
<span class="fc" id="L67">					queries.add(topic);</span>
				}
<span class="fc" id="L69">			}</span>
<span class="fc" id="L70">		}</span>
		try {
<span class="fc" id="L72">			WikipediaUtils2.getInstance(getParameterStore()).addToWordCache(queries);</span>
<span class="fc bfc" id="L73" title="All 2 branches covered.">			for (int i=0;i&lt;document.tokens().size();i++) {</span>
<span class="fc" id="L74">				CoreLabel token = document.tokens().get(i);</span>
				try {
<span class="fc" id="L76">					String topic = scoreLemma(token);</span>
<span class="fc bfc" id="L77" title="All 2 branches covered.">					if (topic != null) {</span>
<span class="fc" id="L78">						String wordCache = WikipediaUtils2.getInstance(getParameterStore()).getWordCache(token.lemma());</span>
<span class="pc bpc" id="L79" title="1 of 4 branches missed.">						if (wordCache != null &amp;&amp; !wordCache.equals(&quot;&quot;)) {</span>
							//Map&lt;String, List&lt;String&gt;&gt; scoreMap = new HashMap&lt;String, List&lt;String&gt;&gt;();
							//scoreMap.put(toAlphaNumeric(token.lemma()), Arrays.asList(wordCache));
<span class="fc" id="L82">							token.set(getAnnotationClass(), wordCache);</span>
						}
					}
				}
<span class="nc" id="L86">				catch (Throwable t) {</span>
<span class="nc" id="L87">					logger.error(&quot;wtf?&quot;, t);</span>
<span class="fc" id="L88">				}</span>
			}
<span class="fc" id="L90">			WikipediaUtils2.getInstance(getParameterStore()).pruneWordCache();</span>
		}
<span class="nc" id="L92">		catch (Exception e) {</span>
<span class="nc" id="L93">			logger.error(e);</span>
<span class="fc" id="L94">		}</span>
<span class="fc" id="L95">	}</span>
	
/*	@SuppressWarnings(&quot;unchecked&quot;)
	@Override
	public void annotate(Annotation annotation) {
		CoreDocument document = new CoreDocument(annotation);
		for (CoreSentence sentence : document.sentences()) {
			for (CoreLabel token : sentence.tokens()) {
				Map&lt;String, List&lt;String&gt;&gt; scoreMap = new HashMap&lt;String, List&lt;String&gt;&gt;();
				String topic = scoreToken(token);
				if (topic != null) {
					try {
						String pageText = WikipediaUtils.getInstance().getWikipediaPageText(topic);
						if (pageText != null &amp;&amp; pageText.length() &gt; 0 &amp;&amp; pageText.indexOf(&quot;.&quot;) &gt; -1 ) {
							scoreMap.put(token.lemma(), Arrays.asList(pageText.substring(0, pageText.indexOf(&quot;.&quot;)).trim()));
							token.set(getAnnotationClass(), scoreMap);
						}
					}
					catch (Exception e) {
						logger.error(e);
					}
				}

			}
		}
		score(document);
	}*/

	@Override
	public String getDescription() {
<span class="fc" id="L125">		return &quot;Wikipedia gloss (first sentence of page body) if NN,NNS,NNP,NNPS.&quot;;</span>
	}

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>